{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tensorboard and its Uses in Machine Learning**\n",
    "## **Written by:** Aarish Asif Khan\n",
    "## **Date:** 13 January 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first step\n",
    "# importing the libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Explanation of the above Code**\n",
    "- In the above code, we imported some useful libraries in order to use tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up log directory \"logs\" and a function that prepends the time of a run\n",
    "root_logdir = os.path.join(os.curdir, \"logs\")\n",
    "\n",
    "def get_run_logdir(name: str = \"\"):\n",
    "  \"\"\"\n",
    "  Prepends time of a run to the specified name of the run.\n",
    "  This new string (with time prepended) will be used as directory name.\n",
    "  \"\"\"\n",
    "  import time\n",
    "  run_id = time.strftime(\"%m_%d-%H_%M\")\n",
    "  run_name = run_id + f\"_{name}\"\n",
    "  return os.path.join(root_logdir, run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Explanation of the above Code**\n",
    "- This code sets up a log directory named \"logs\" and defines a function, get_run_logdir, which generates a directory path based on the current time and a provided name. The resulting directory structure is \"logs/MM_DD-HH_MM_name\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# load dataset (fmnist) - note: The dataset is reduced to allow for faster computations\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255, X_train_full[5000:35000] / 255\n",
    "y_valid, y_train = y_train_full[:5000]      , y_train_full[5000:35000]\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Explanation of above Code**\n",
    "- This code loads the Fashion MNIST dataset, reduces its size for faster computation, and preprocesses it by dividing pixel values by 255. The dataset is then split into validation, training, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some training hyperparams\n",
    "EPOCHS = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Explanation of the above Code**\n",
    "- This code sets a hyperparameter EPOCHS to the value of 13, indicating the number of times a machine learning model will iterate over the entire training dataset during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\User\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "model1 = keras.models.Sequential([\n",
    "      layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
    "      layers.Conv2D(filters=32, kernel_size=3),\n",
    "      layers.BatchNormalization(),\n",
    "      layers.ReLU(),\n",
    "      layers.MaxPool2D(),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(32, activation='relu'),\n",
    "      layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Explanation of the Above Code**\n",
    "- This code defines a convolutional neural network (CNN) model using Keras. The model consists of convolutional layers, batch normalization, activation functions, max-pooling, dropout, and fully connected layers. It is designed for image classification with 10 output classes. The model is compiled with the sparse categorical crossentropy loss, the Adam optimizer, and accuracy as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "WARNING:tensorflow:From c:\\Users\\User\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\User\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "938/938 [==============================] - 38s 38ms/step - loss: 0.4676 - accuracy: 0.8318 - val_loss: 0.3351 - val_accuracy: 0.8816\n",
      "Epoch 2/13\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.3131 - accuracy: 0.8850 - val_loss: 0.2947 - val_accuracy: 0.8982\n",
      "Epoch 3/13\n",
      "938/938 [==============================] - 33s 36ms/step - loss: 0.2708 - accuracy: 0.9013 - val_loss: 0.2851 - val_accuracy: 0.8952\n",
      "Epoch 4/13\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.2399 - accuracy: 0.9111 - val_loss: 0.2769 - val_accuracy: 0.9036\n",
      "Epoch 5/13\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.2148 - accuracy: 0.9199 - val_loss: 0.3393 - val_accuracy: 0.8854\n",
      "Epoch 6/13\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.2014 - accuracy: 0.9244 - val_loss: 0.3346 - val_accuracy: 0.8840\n",
      "Epoch 7/13\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.1792 - accuracy: 0.9321 - val_loss: 0.2896 - val_accuracy: 0.8992\n",
      "Epoch 8/13\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.1656 - accuracy: 0.9384 - val_loss: 0.3178 - val_accuracy: 0.8978\n",
      "Epoch 9/13\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.1514 - accuracy: 0.9442 - val_loss: 0.3002 - val_accuracy: 0.9066\n",
      "Epoch 10/13\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.1408 - accuracy: 0.9476 - val_loss: 0.3160 - val_accuracy: 0.9048\n",
      "Epoch 11/13\n",
      "938/938 [==============================] - 36s 39ms/step - loss: 0.1253 - accuracy: 0.9535 - val_loss: 0.3302 - val_accuracy: 0.9064\n",
      "Epoch 12/13\n",
      "938/938 [==============================] - 34s 37ms/step - loss: 0.1178 - accuracy: 0.9573 - val_loss: 0.3500 - val_accuracy: 0.9004\n",
      "Epoch 13/13\n",
      "938/938 [==============================] - 33s 35ms/step - loss: 0.1080 - accuracy: 0.9606 - val_loss: 0.3594 - val_accuracy: 0.9062\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: This is where the callback is defined and used\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(get_run_logdir(\"1conv\"), \n",
    "                                             histogram_freq=1,)\n",
    "history = model1.fit(X_train, y_train, epochs=EPOCHS, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Explanation of the above Code**\n",
    "- This code sets up a TensorBoard callback, specifying the log directory using a function (get_run_logdir) and the model's training history. During the training of model1, the TensorBoard callback logs data for visualization, such as loss and accuracy, and histograms of layer activations, and it saves them in the specified log directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new sequential model \n",
    "model2 = keras.models.Sequential([\n",
    "      layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
    "      layers.Conv2D(filters=32, kernel_size=3),\n",
    "      layers.BatchNormalization(),\n",
    "      layers.ReLU(),\n",
    "      layers.MaxPool2D(),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Conv2D(filters=32, kernel_size=3),\n",
    "      layers.BatchNormalization(),\n",
    "      layers.ReLU(),\n",
    "      layers.MaxPool2D(),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(32, activation='relu'),\n",
    "      layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Explanation of the above Code**\n",
    "- This code defines a new sequential neural network model (model2) using Keras with additional convolutional layers compared to model1. It includes convolutional layers, batch normalization, activation functions, max-pooling, dropout, and fully connected layers. The model is designed for image classification with 10 output classes. It is compiled with the sparse categorical crossentropy loss, the Adam optimizer, and accuracy as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "938/938 [==============================] - 30s 29ms/step - loss: 0.5976 - accuracy: 0.7778 - val_loss: 0.3975 - val_accuracy: 0.8582\n",
      "Epoch 2/13\n",
      "938/938 [==============================] - 29s 31ms/step - loss: 0.4110 - accuracy: 0.8496 - val_loss: 0.3837 - val_accuracy: 0.8558\n",
      "Epoch 3/13\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.3599 - accuracy: 0.8670 - val_loss: 0.3131 - val_accuracy: 0.8846\n",
      "Epoch 4/13\n",
      "938/938 [==============================] - 35s 37ms/step - loss: 0.3307 - accuracy: 0.8774 - val_loss: 0.2842 - val_accuracy: 0.8950\n",
      "Epoch 5/13\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.3125 - accuracy: 0.8846 - val_loss: 0.2847 - val_accuracy: 0.8970\n",
      "Epoch 6/13\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.2932 - accuracy: 0.8902 - val_loss: 0.2789 - val_accuracy: 0.8974\n",
      "Epoch 7/13\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.2770 - accuracy: 0.8958 - val_loss: 0.2901 - val_accuracy: 0.8952\n",
      "Epoch 8/13\n",
      "938/938 [==============================] - 25s 27ms/step - loss: 0.2656 - accuracy: 0.8996 - val_loss: 0.2649 - val_accuracy: 0.9014\n",
      "Epoch 9/13\n",
      "938/938 [==============================] - 24s 25ms/step - loss: 0.2541 - accuracy: 0.9038 - val_loss: 0.2705 - val_accuracy: 0.9012\n",
      "Epoch 10/13\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.2427 - accuracy: 0.9096 - val_loss: 0.2763 - val_accuracy: 0.9014\n",
      "Epoch 11/13\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.2337 - accuracy: 0.9123 - val_loss: 0.2562 - val_accuracy: 0.9042\n",
      "Epoch 12/13\n",
      "938/938 [==============================] - 24s 25ms/step - loss: 0.2225 - accuracy: 0.9144 - val_loss: 0.2746 - val_accuracy: 0.9042\n",
      "Epoch 13/13\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.2216 - accuracy: 0.9168 - val_loss: 0.2714 - val_accuracy: 0.8998\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: This is where the callback is defined and used\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(get_run_logdir(\"2conv\"),\n",
    "                                             histogram_freq=1,)\n",
    "history = model2.fit(X_train, y_train, epochs=EPOCHS, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Explanation of the above Code**\n",
    "- Like we used the CallBack function in the previous model1, we are also going to make a CallBack function for our other Sequential model2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-be933439ae9023ad\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-be933439ae9023ad\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load tensorboard\n",
    "%load_ext tensorboard\n",
    "# start tensorboard inside the notebook. Outside of the notebook, \n",
    "# use tensorboard --logdir=./logs\n",
    "%tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Explanation of the above Code**\n",
    "- This code loads the TensorBoard extension and starts TensorBoard within the notebook. The %load_ext tensorboard command enables the TensorBoard extension, and %tensorboard --logdir=./logs launches TensorBoard to visualize logs stored in the \"logs\" directory. This is typically used for monitoring and analyzing the training process of machine learning models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
